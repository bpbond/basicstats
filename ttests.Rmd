---
title: "Testing for group differences"
author: "Ben"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(20211002)

library(tibble)
library(tidyr)
library(ggplot2)
theme_set(theme_bw())
```

# How do we test for group differences?

Consider R's `sleep` dataset:

```{r, eval=FALSE}
?sleep
```

>Data which show the effect of two soporific drugs (increase in hours of sleep compared to control) on 10 patients. A data frame with 20 observations on 3 variables.

```{r plot-sleep}
tapply(sleep$extra, sleep$group, summary)
ggplot(sleep, aes(group, extra)) + 
  geom_boxplot() + 
  geom_point(color = "blue", size = 3)
```

**How do we know if the differences between these groups are _statistically significant?_**

To answer this question, we need to understand:

* Random variables
* The scope of our inference: populations versus samples
* Sample statistics: variance and standard deviation
* The normal distribution
* Hypothesis testing
* The Student's t-test

# Random variables

A variable is an _attribute_ of the data. They fall into two categories:

• Quantitative variables are those for which the value has numerical meaning. The value refers to a _specific amount_ of something.
• Categorical variables indicate group membership. Gender is a classic example.

https://orla.osd.wednet.edu/common/pages/UserFile.aspx?fileId=30749993

A closely related idea is that of _random variables_:

>A random variable is a numerical description of the outcome of a statistical experiment. A random variable that may assume only a finite number or an infinite sequence of values is said to be discrete; one that may assume any value in some interval on the real number line is said to be continuous.

From [Encyclopedia Brittanica](https://www.britannica.com/science/statistics/Random-variables-and-probability-distributions). 

# Population vs. Sample

When you conduct a study, you define your population of interest. This is the entire set of elements that possess the characteristics of interest. In reality, you will rarely obtain observations or measurements on all elements of interest in a particular study simply because some of them will be inaccessible for a wide variety of reasons or it will be impractical to do so.

* A population includes all elements of interest.
* A sample consists of a subset of observations from a population. As a result, multiple samples can be drawn from the same population.

The nomenclature, statistical formulas, notation, and vary depending on whether your analyzing a population or sample.

# Variance and standard deviation

variance is the sum of deviations from the mean

The standard deviation is the square root of the variance. By taking the square root, we return the measure to the same scale as the mean. It indicates how close the data is to the mean.


# The normal distribution of a _population_

https://en.wikipedia.org/wiki/Normal_distribution

Most statistics assume a _normal distribution_, meaning that the data approximate a bell-shaped curve. In normal distributions, 68% of the data fall within ±1 standard deviation from the mean; 95% within 2 standard deviations, and 99% within 3 standard deviations.

```{r normal, echo=FALSE}
add_sd_lines <- function(p, n_sd, ht, clr, lbl) {
  p + annotate(geom = "segment", x = -n_sd, y = ht, xend = n_sd, yend = ht, 
               arrow = arrow(ends = "both"), size = 0.75, color = clr) +
    geom_vline(xintercept = c(-n_sd, n_sd), color = clr, linetype = 2) +
    geom_label(x = 0, y = ht, label = lbl, color = clr)
}

distribution_graph_theme <- function() {
  theme_minimal() %+replace%
    theme(axis.text.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.text.x = element_text(face = "bold"),
          axis.title.x = element_text(size = 12, face = "bold"))
}

p <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
  stat_function(fun = dnorm, size = 1) +
  distribution_graph_theme() +
  labs(x = "Standard deviations", y = "")
p <- add_sd_lines(p, 1, 0.2, "lightblue", "68.2%")
p <- add_sd_lines(p, 2, 0.15, "blue", "95.4%")
p <- add_sd_lines(p, 3, 0.1, "darkblue", "99.7%")
p
```

# Student's t distribution

From [Wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-distribution):

>In probability and statistics, Student's t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arise when estimating the mean of a **normally distributed population** in situations where the **sample size is small** and the population's **standard deviation is unknown**.

```{r students, echo=FALSE}
dat <- data.frame()
for(df in c(1, 2, 5, 10, 20)) {
  dat <- rbind(dat, tibble(x = seq(-4, 4, by = 0.05), 
                           y = dt(x, df = df),
                           df = df))
}
dat$df <- as.factor(dat$df)
ggplot(dat, aes(x, y)) + geom_line(aes(color = df)) +
  scale_color_discrete("Degrees of\nfreedom") +
  stat_function(fun = dnorm, linetype = 2) +
  distribution_graph_theme() +
  theme(legend.position = c(0.8, 0.7)) +
  labs(x = "Standard deviations", y = "") +
  annotate("text", x = -2, y = 0.3, label = "Dashed line\nshows normal\ndistribution", size = 3)
```

# Hypothesis testing


# The Student's t test

```{r}
group1 <- sleep[sleep$group == 1,]$extra
group2 <- sleep[sleep$group == 2,]$extra
t.test(group1, group2)
```

# Paired versus unpaired

**But wait!** Let's look again at `sleep` (only showing a few rows for clarity):

```{r, echo=FALSE}
sleep[sleep$ID %in% c(1, 2, 9, 10),] %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

`sleep` does not consist of **two random samples drawn from a population**;
rather, it is 10 random subjects (the `ID` column; see the help page) 
_measured twice_, once for each drug. Visually:

```{r plot-paired-sleep, echo=FALSE}
sleep2 <- pivot_wider(sleep, names_from =  "group", values_from = "extra")

ggplot(sleep, aes(group, extra)) + 
  geom_boxplot(color = "lightgrey") + 
  geom_point(color = "blue", size = 3) + 
  geom_segment(data = sleep2, x = 1, xend = 2, aes(y = `1`, yend = `2`),
               color = "blue", linetype = 2, size = 0.25)
```

This means that we can use a **paired t-test**, which gives us
more statistical power:

```{r}
t.test(group1, group2, paired = TRUE)
```


# The End

The repository for this document is [here](https://github.com/bpbond/linear).

```{r, echo=FALSE}
sessionInfo()
```
